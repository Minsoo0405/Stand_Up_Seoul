{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import ttest_ind,f_oneway\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# 한글 폰트 해결\n",
    "plt.rcParams['font.family'] = 'AppleGothic'\n",
    "\n",
    "# 노트북 안에 그래프를 그리기 위해\n",
    "%matplotlib inline\n",
    "\n",
    "# 그래프에서 격자로 숫자 범위가 눈에 잘 띄도록 ggplot 스타일을 사용\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# 그래프에서 마이너스 폰트 깨지는 문제에 대한 대처\n",
    "mpl.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "pd.options.display.float_format = '{:.3f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 불러오기\n",
    "data = pd.read_parquet('./2008~2023_data.parquet')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 변수 설명\n",
    "- Date : 날짜 \n",
    "- Station_num : 역 번호\n",
    "- Line_num : 지하철 호선\n",
    "- Station : 역 이름\n",
    "- holiday : 공휴일(토요일, 일요일 포함)\n",
    "- weekday : 요일 (일요일 :0, 월요일:1, ... 토요일 : 6)\n",
    "- geton : 승차 인원\n",
    "- getoff : 하차 인원\n",
    "- get_all : 승하차 인원\n",
    "- Temp : 온도\n",
    "- Rainfall_amt : 강수량\n",
    "- Wind_speed : 풍속\n",
    "- Humidity : 습도\n",
    "- Snow_amt : 적설량\n",
    "- Temp_mean : 하루 평균 온도\n",
    "- Rainfall_amt_mean : 하루 평균 강수량\n",
    "- Wind_speed_mean : 하루 평균 풍속\n",
    "- Humidity_mean : 하루 평균 습도\n",
    "- Snow_amt_mean : 하루 평균 적설량\n",
    "- Rainfall_amt_sum : 하루 강수량 합계\n",
    "- Snow_amt_sum : 하루 적설량 합계 \n",
    "- Temp_max : 하루 최고 기온\n",
    "- Temp_min : 하루 최저 기온\n",
    "- Temp_diff : 일교차\n",
    "- hour : 시간\n",
    "- year : 년도\n",
    "- month : 월\n",
    "- day : 일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Calculate the IQR for each hour\n",
    "grouped = data.groupby('hour')['log_get_all']\n",
    "quartiles = grouped.quantile([0.25, 0.75])\n",
    "lower_quartile = quartiles.loc[:, 0.25]\n",
    "upper_quartile = quartiles.loc[:, 0.75]\n",
    "iqr = upper_quartile - lower_quartile\n",
    "\n",
    "# Define the lower and upper bounds for outliers\n",
    "lower_bound = lower_quartile - 1.5 * iqr\n",
    "upper_bound = upper_quartile + 1.5 * iqr\n",
    "\n",
    "# Identify outliers\n",
    "outliers = data[(data['log_get_all'] < lower_bound.loc[data['hour']].values) |\n",
    "                     (data['log_get_all'] > upper_bound.loc[data['hour']].values)]\n",
    "\n",
    "# Display the outliers\n",
    "outliers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 결측치 확인\n",
    "- 데이터 결측지 없음 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['rainy'] = data['Rainfall_amt']>0.0\n",
    "\n",
    "data['rainy'] = data['rainy'].astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['log_get_all'] = np.log1p(data['get_all'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 승하차인원의 정규성 검정\n",
    "- 정규성 검정 진행 (p-value < 0.05 이므로 귀무가설 기각.) \n",
    "- 승하차 인원 데이터는 정규분포를 띄지 않는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 귀무가설 : 승하차 인원 데이터 분포는 정규 분포이다.\n",
    "# 대립가설 : 승하차 인원 데이터 분포는 정규 분포를 띄지 않을것이다.\n",
    "stats.normaltest(data['get_all'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 귀무가설 : 로그 스케일링 후 승하차 인원 데이터 분포는 정규 분포이다.\n",
    "# 대립가설 : 로그 스케일링 후 승하차 인원 데이터 분포는 정규 분포를 띄지 않을것이다.\n",
    "stats.normaltest(data['log_get_all'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 변수별 유의성 검정\n",
    "- 제공된 p-value를 기반으로 회귀 모델에서 모든 변수가 목표 변수에 통계적으로 유의미한 영향을 미친다는 결론을 내릴 수 있다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "\n",
    "Station_num_data = data[['get_all', 'Station_num']]\n",
    "line_data = data[['get_all', 'Line_num']]\n",
    "weekday_data = data[['get_all', 'weekday']]\n",
    "hour_data = data[['get_all', 'hour']]\n",
    "year_data = data[['get_all', 'year']]\n",
    "month_data = data[['get_all', 'month']]\n",
    "day_data = data[['get_all', 'day']]\n",
    "\n",
    "station_groups = []\n",
    "for num in data.Station_num.unique():\n",
    "    group = Station_num_data[Station_num_data['Station_num'] == num]['get_all']\n",
    "    station_groups.append(group)\n",
    "\n",
    "line_groups = []\n",
    "for line in data.Line_num.unique():\n",
    "    group = line_data[line_data['Line_num'] == line]['get_all']\n",
    "    line_groups.append(group)\n",
    "\n",
    "weekday_groups = []\n",
    "for weekday in data.weekday.unique():\n",
    "    group = weekday_data[weekday_data['weekday'] == weekday]['get_all']\n",
    "    weekday_groups.append(group)\n",
    "\n",
    "hour_groups = []\n",
    "for hour in data.hour.unique():\n",
    "    group = hour_data[hour_data['hour'] == hour]['get_all']\n",
    "    hour_groups.append(group)\n",
    "\n",
    "year_groups = []\n",
    "for year in data.year.unique():\n",
    "    group = year_data[year_data['year'] == year]['get_all']\n",
    "    year_groups.append(group)\n",
    "\n",
    "month_groups = []\n",
    "for month in data.month.unique():\n",
    "    group = month_data[month_data['month'] == month]['get_all']\n",
    "    month_groups.append(group)\n",
    "\n",
    "day_groups = []\n",
    "for day in data.day.unique():\n",
    "    group = day_data[day_data['day'] == day]['get_all']\n",
    "    day_groups.append(group)\n",
    "\n",
    "f_stat_station, p_value_station = f_oneway(*station_groups)\n",
    "f_stat_line, p_value_line = f_oneway(*line_groups)\n",
    "f_stat_weekday, p_value_weekday = f_oneway(*weekday_groups)\n",
    "f_stat_hour, p_value_hour = f_oneway(*hour_groups)\n",
    "f_stat_year, p_value_year = f_oneway(*year_groups)\n",
    "f_stat_month, p_value_month = f_oneway(*month_groups)\n",
    "f_stat_day, p_value_day = f_oneway(*day_groups)\n",
    "\n",
    "# Print the p-values\n",
    "print(\"Station Significance Probability (p-value):\", p_value_station)\n",
    "print(\"Line Significance Probability (p-value):\", p_value_line)\n",
    "print(\"Weekday Significance Probability (p-value):\", p_value_weekday)\n",
    "print(\"Hour Significance Probability (p-value):\", p_value_hour)\n",
    "print(\"Year Significance Probability (p-value):\", p_value_year)\n",
    "print(\"Month Significance Probability (p-value):\", p_value_month)\n",
    "print(\"Day Significance Probability (p-value):\", p_value_day)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Two Sample T Test (이표본 평균검정)\n",
    "- 두 집단 평균의 차이가 있는지 검정\n",
    "- 집단이 서로 등분산성을 보이지 않을 때 \n",
    "\n",
    "- Levene Test : 두 집단 분산의 차이가 있는지 검정\n",
    "    - 귀무가설 : 두 집단의 분산이 같다.\n",
    "    - 대립가설 : 두 집단의 분산이 다르다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 두 집단의 등분산 검정\n",
    "# 귀무 가설 : 비가 온 날과 비가 오지 않은 날의 승하차 인원의 분산의 차이가 없다.\n",
    "# 대립 가설 : 비가 온 날과 비가 오지 않은 날의 승하차 인원의 분산의 차이가 있다.\n",
    "rainy_data = data[['get_all', 'rainy']]\n",
    "\n",
    "rainy_o = rainy_data[rainy_data['rainy'] == 1]\n",
    "rainy_x = rainy_data[rainy_data['rainy'] == 0]\n",
    "\n",
    "stats.levene(rainy_o['get_all'], rainy_x['get_all'])\n",
    "\n",
    "# p-value < 0.05 (귀무가설 기각, 대립가설 참)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 두 집단의 등분산 검정\n",
    "# 귀무 가설 : 공휴일과 공휴일이 아닌 날의 승하차 인원의 분산의 차이가 없다.\n",
    "# 대립 가설 : 공휴일과 공휴일이 아닌 날의 승하차 인원의 분산의 차이가 있다.\n",
    "\n",
    "holiday_data = data[['get_all', 'holiday']]\n",
    "\n",
    "holiday_o = holiday_data[holiday_data['holiday'] == 1]\n",
    "holiday_x = holiday_data[holiday_data['holiday'] == 0]\n",
    "\n",
    "stats.levene(holiday_o['get_all'], holiday_x['get_all'])\n",
    "\n",
    "# p-value < 0.05 (귀무가설 기각, 대립가설 참)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 이표본 평균 검정 진행\n",
    "- 귀무가설 : 공휴일, 비온날과 공휴일이 아닌날, 비가 오지 않은날 승하차 평균인원의 차이가 없다.\n",
    "- 대립가설 : 공휴일, 비온날과 공휴일이 아닌날, 비가 오지 않은날 승하차 평균인원의 차이가 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the relevant columns for the analysis\n",
    "rainy_data = data[['get_all', 'rainy']]\n",
    "holiday_data = data[['get_all', 'holiday']]\n",
    "\n",
    "rainy_o = rainy_data[rainy_data['rainy'] == 1]['get_all']\n",
    "rainy_x = rainy_data[rainy_data['rainy'] == 0]['get_all']\n",
    "\n",
    "holiday_o = holiday_data[holiday_data['holiday'] == 1]['get_all']\n",
    "holiday_x = holiday_data[holiday_data['holiday'] == 0]['get_all']\n",
    "\n",
    "# Perform the t-test\n",
    "t_stat_rainy, p_value_rainy = ttest_ind(rainy_x, rainy_o)\n",
    "t_stat_holiday, p_value_holiday = ttest_ind(holiday_x, rainy_o)\n",
    "\n",
    "\n",
    "# Print the p-value\n",
    "print(\"Rainy Significance Probability (p-value):\", p_value_rainy)\n",
    "print(\"Holiday Significance Probability (p-value):\", p_value_holiday)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 변수별 상관관계 확인 \n",
    "- 승하차인원과 상관관계가 높은 것은 호선, 역번호, 공휴일, 시간 순으로 확인 가능."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Select the relevant columns for correlation analysis\n",
    "columns_of_interest = ['get_all', 'Line_num', 'Station_num', 'holiday', 'weekday', 'Temp', 'Rainfall_amt',\n",
    "                       'Wind_speed', 'Humidity', 'Snow_amt', 'year', 'month', 'day', 'hour']\n",
    "correlation_df = data[columns_of_interest]\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "correlation_matrix = correlation_df.corr()\n",
    "\n",
    "# Create the heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap='coolwarm')\n",
    "\n",
    "# Add a title\n",
    "plt.title(\"Correlation Heatmap\")\n",
    "\n",
    "# Display the heatmap\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터가 너무 커서 시각화 할때 커널이 죽는 문제를 해결하기 위해 샘플데이터로 EDA 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = data.sample(200000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 승하차인원 정규분포 확인 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subplots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "# Plot histogram for 'get_all'\n",
    "sns.histplot(data=sample_df, x='get_all', bins=30, kde=True, ax=axes[0])\n",
    "axes[0].set_xlabel('get_all')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].set_title('Distribution of get_all')\n",
    "\n",
    "# Plot histogram for 'log_get_all'\n",
    "sns.histplot(data=sample_df, x='log_get_all', bins=30, kde=True, ax=axes[1])\n",
    "axes[1].set_xlabel('log_get_all')\n",
    "axes[1].set_ylabel('Count')\n",
    "axes[1].set_title('Distribution of log_get_all')\n",
    "\n",
    "# Adjust spacing between subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 날짜별 승하차 인원 분석\n",
    "- 연도별 승하차 인원은 2008~2019년도 까지 차이가 없다가 2020년 이후로 급격하게 줄어드는 것을 확인 할 수 있다.\n",
    "- 월별 승하차 인원은 1,2,7,8월이 상대적으로 적은 것을 확인 할 수 있다.\n",
    "- 일별 승하차 인원은 거의 차이가 없는것을 확인 할 수 있다.\n",
    "- 시간별 승하차 인원은 출퇴근 시간인 8시와 18시에 많은 것을 확인 할 수 있다.\n",
    "- 요일별 승하차 인원은 금요일이 가장 많은 것을 확인 할 수 있었으며, 주말은 평일보다 적은 것을 확인 할 수 있었다.\n",
    "- 12시부터 15시 사이 평일 보다 공휴일에 승하차 인원이 더 많은 것을 확인 할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, axes = plt.subplots(nrows=2, ncols=3)\n",
    "figure.set_size_inches(25,10)\n",
    "\n",
    "sns.barplot(data=sample_df, x=\"year\", y=\"get_all\", ax=axes[0, 0])\n",
    "sns.barplot(data=sample_df, x=\"month\", y=\"get_all\", ax=axes[0, 1])\n",
    "sns.barplot(data=sample_df, x=\"day\", y=\"get_all\", ax=axes[0, 2])\n",
    "sns.barplot(data=sample_df, x=\"hour\", y=\"get_all\", ax=axes[1, 0])\n",
    "sns.barplot(data=sample_df, x=\"weekday\", y=\"get_all\", ax=axes[1, 1])\n",
    "sns.pointplot(data = sample_df, x = 'hour', y = 'get_all', hue = 'holiday', ax=axes[1, 2])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 날씨별 승하차 인원 분석\n",
    "- 날씨별 승하차 인원이 선형성이 없는 것을 확인 할 수 있었음.\n",
    "- 출퇴근 시간을 제외한 시간에는 비가 온날보다 비가 오지 않은날에 승하차 인원이 조금더 많은 것을 확인 할 수 있었음.\n",
    "- 강수량과 적설량이 0이 많이 있는 것을 확인 할 수 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, axes = plt.subplots(nrows=2, ncols=3)\n",
    "figure.set_size_inches(25, 10)\n",
    "\n",
    "sns.scatterplot(data=sample_df, x=\"Temp_mean\", y=\"get_all\", hue='rainy', ax=axes[0, 0])\n",
    "sns.scatterplot(data=sample_df, x=\"Humidity_mean\", y=\"get_all\", hue='rainy', ax=axes[0, 1])\n",
    "sns.scatterplot(data=sample_df, x=\"Wind_speed\", y=\"get_all\", hue='rainy', ax=axes[0, 2])\n",
    "sns.scatterplot(data=sample_df, x=\"Snow_amt\", y=\"get_all\", hue='rainy', ax=axes[1, 0])\n",
    "sns.scatterplot(data=sample_df, x=\"Rainfall_amt\", y=\"get_all\", ax=axes[1, 1])\n",
    "\n",
    "axes[1, 2].remove()\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "figure, axes = plt.subplots(nrows=1, ncols=1)\n",
    "figure.set_size_inches(25, 10)\n",
    "\n",
    "sns.pointplot(data=sample_df, x=\"hour\", y=\"get_all\",hue='rainy')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 호선별 승하차 인원 분석\n",
    "- 2호선, 1호선, 4호선, 3호선 순으로 승하차 인원이 많은 것을 확인 할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, ax8 = plt.subplots(nrows=1, ncols=1)\n",
    "figure.set_size_inches(25, 10)\n",
    "sns.pointplot(data = sample_df, x = 'hour', y = 'get_all', hue = 'Line_num', ax = ax8)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 날짜 데이터 분포와 이상치 확인\n",
    "- 날짜,요일별 이상치를 확인 하였을때 이상치가 다소 있는것으로 확인 되어짐 출퇴근 시간에 영향을 받았을 것이라 추정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, axes = plt.subplots(nrows=2, ncols=3)\n",
    "figure.set_size_inches(25, 10)\n",
    "\n",
    "sns.boxplot(data=sample_df, x=\"hour\", y=\"get_all\", ax=axes[0, 0])\n",
    "sns.boxplot(data=sample_df, x=\"month\", y=\"get_all\", ax=axes[0, 1])\n",
    "sns.boxplot(data=sample_df, x=\"day\", y=\"get_all\", ax=axes[0, 2])\n",
    "sns.boxplot(data=sample_df, x=\"year\", y=\"get_all\", ax=axes[1, 0])\n",
    "sns.boxplot(data=sample_df, x=\"weekday\", y=\"get_all\", ax=axes[1, 1])\n",
    "sns.boxplot(data=sample_df, x=\"holiday\", y=\"get_all\", ax=axes[1, 2])\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 다중공선성 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Select the relevant columns for correlation analysis\n",
    "columns_of_interest = ['Temp','Temp_mean']\n",
    "correlation_df = data[columns_of_interest]\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "correlation_matrix = correlation_df.corr()\n",
    "\n",
    "# Create the heatmap\n",
    "plt.figure(figsize=(3, 3))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap='coolwarm')\n",
    "\n",
    "# Display the heatmap\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the relevant columns for correlation analysis\n",
    "columns_of_interest = ['Rainfall_amt','Rainfall_amt_mean']\n",
    "correlation_df = data[columns_of_interest]\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "correlation_matrix = correlation_df.corr()\n",
    "\n",
    "# Create the heatmap\n",
    "plt.figure(figsize=(3, 3))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap='coolwarm')\n",
    "\n",
    "# Display the heatmap\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the relevant columns for correlation analysis\n",
    "columns_of_interest = ['Humidity','Humidity_mean']\n",
    "correlation_df = data[columns_of_interest]\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "correlation_matrix = correlation_df.corr()\n",
    "\n",
    "# Create the heatmap\n",
    "plt.figure(figsize=(3, 3))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap='coolwarm')\n",
    "\n",
    "# Display the heatmap\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 라이브러리 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os, glob, gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns',500)\n",
    "pd.set_option('display.max_rows',250)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 공휴일 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holiday = pd.read_csv('./subway/holiday.csv', encoding='cp949')\n",
    "holiday['날짜1'] = pd.to_datetime(holiday['날짜1'])\n",
    "holiday\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 지하철 데이터 불러오기 \n",
    "- 불러온 데이터에서 역 호선을 1~8 으로 매핑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# './subway/' 폴더 내의 '* 20* *.csv' 파일들을 모두 찾아서 리스트로 저장\n",
    "all_subway = glob.glob(os.path.join('./subway/', '* 20* *.csv'))\n",
    "\n",
    "# 호선 번호와 호선 이름을 매핑한 딕셔너리 생성\n",
    "hosun = {f'{i}호선': i for i in range(1, 9)}\n",
    "print(hosun)\n",
    "\n",
    "# all_subway 리스트의 각 파일에 대해 반복문 실행\n",
    "for idx, f in enumerate(all_subway):\n",
    "    # 파일을 읽어서 DataFrame으로 저장\n",
    "    subway = pd.read_csv(f, encoding='cp949', low_memory=False)\n",
    "    \n",
    "    # '00~01' 열의 결측값을 0으로 대체\n",
    "    subway['00~01'].fillna(0, inplace=True)\n",
    "    \n",
    "    # 5번째 열부터 끝까지 각 열에 대해 데이터 타입 변환 작업 수행\n",
    "    for c in subway.columns[5:]:\n",
    "        try:\n",
    "            # ',' 문자 제거 후 문자열을 숫자로 변환\n",
    "            subway[c] = subway[c].str.replace(',', '')\n",
    "            subway[c] = pd.to_numeric(subway[c], errors='ignore')\n",
    "            subway[c] = subway[c].astype(np.float64)\n",
    "        except Exception as e:\n",
    "            # 변환 중 에러가 발생하면 그대로 유지\n",
    "            subway[c] = pd.to_numeric(subway[c], errors='ignore')\n",
    "            subway[c] = subway[c].astype(np.float64)\n",
    "    \n",
    "    # 첫 번째 파일인 경우 all_sub에 subway를 할당하고, 그 이후 파일은 이어붙임\n",
    "    all_sub = subway if idx == 0 else pd.concat([all_sub, subway], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '역번호' 열의 데이터 타입을 숫자로 변환하되, 변환할 수 없는 값은 NaN으로 처리\n",
    "all_sub['역번호'] = pd.to_numeric(all_sub['역번호'], errors='coerce')\n",
    "\n",
    "# '호선' 열의 결측값을 0으로 대체\n",
    "all_sub['호선'].fillna(0, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '역번호' 열의 결측값을 뒤의 다음 유효한 값으로 채움 (뒤로 채우기)\n",
    "all_sub['역번호'].fillna(method='bfill', inplace=True)\n",
    "\n",
    "# '역번호' 열의 데이터 타입을 64비트 정수형으로 변환\n",
    "all_sub['역번호'] = all_sub['역번호'].astype(np.int64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sub[all_sub['역번호'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '역번호' 열의 고유한 값들을 가져와서 반복문 수행\n",
    "st = {st_num: list(set(all_sub[all_sub['역번호'] == st_num]['역명']))[0].strip()\n",
    "      for st_num in all_sub['역번호'].unique()}\n",
    "\n",
    "# 결과로 생성된 딕셔너리 출력\n",
    "st\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 빈 딕셔너리 생성\n",
    "st_line_dict = {}\n",
    "\n",
    "# '역번호' 열의 고유한 값들을 가져와서 반복문 수행\n",
    "for st_num in all_sub['역번호'].unique():\n",
    "    # '역번호'가 특정 값인 행들을 필터링하여 '호선' 열의 고유한 값들을 가져옴\n",
    "    st_line = list(set(all_sub[all_sub['역번호'] == st_num]['호선']))\n",
    "    \n",
    "    # '호선' 값 중에서 문자열이 아니고 0이 아닌 값들을 필터링하여 첫 번째 값을 선택\n",
    "    st_line = [l for l in st_line if (isinstance(l, str) is False) and (l != 0)][0]\n",
    "    \n",
    "    # '역번호'를 키(key)로, 해당 '역번호'에 대응하는 '호선'을 값(value)으로 딕셔너리에 추가\n",
    "    st_line_dict[st_num] = st_line\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '역번호' 열의 값을 기준으로 st_line_dict 딕셔너리를 사용하여 '호선' 열의 값을 매핑\n",
    "all_sub['호선'] = all_sub['역번호'].map(st_line_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2008~2023_data_ver1\n",
    "all_sub.to_csv('./2008~2023_data_ver1.csv', encoding='cp949', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pivot_df(df_in, val_name):\n",
    "    # 변환할 시간대 열들을 리스트로 정의\n",
    "    time_columns = ['05~06', '06~07', '07~08', '08~09', '09~10', '10~11', '11~12', '12~13', '13~14',\n",
    "                    '14~15', '15~16', '16~17', '17~18', '18~19', '19~20', '20~21', '21~22', '22~23', '23~24', '00~01']\n",
    "\n",
    "    # melt 함수를 사용하여 데이터프레임을 변환\n",
    "    df_out = pd.melt(df_in, id_vars=['날짜', '호선', '역번호', '역명', '구분'],\n",
    "                     value_vars=time_columns, var_name='시간', value_name=val_name)\n",
    "\n",
    "    # 열 이름 영어로 변경\n",
    "    df_out.columns = ['Date', 'Line_num', 'Station_num', 'Station', 'Division', 'Time', val_name]\n",
    "\n",
    "    # 'Date'와 'Time' 열을 기준으로 정렬\n",
    "    df_out.sort_values(['Date', 'Time'], inplace=True)\n",
    "\n",
    "    # 인덱스 재설정\n",
    "    df_out.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return df_out\n",
    "\n",
    "\n",
    "def merge_holiday(left_df, right_df, left='Date', right='날짜1', how ='left'):\n",
    "    \n",
    "    df_new = pd.merge(left_df, right_df, left_on=left, right_on=right, how=how)\n",
    "    \n",
    "    # 공휴일 컬럼 만들기 공휴일일때 1 아닐때 0\n",
    "    df_new['holiday'] = df_new['휴일명'].apply(lambda x: 1 if pd.notnull(x) else 0)\n",
    "\n",
    "    # 필요없는 컬럼 삭제 \n",
    "    df_new.drop(['날짜1','휴일명'], axis=1, inplace=True)\n",
    "    \n",
    "    df_new['Date'] = pd.to_datetime(df_new['Date'])\n",
    "\n",
    "    # 월요일 : 1, 화요일 : 2, ..., 일요일 : 7\n",
    "    df_new['weekday'] = df_new['Date'].dt.weekday + 1\n",
    "    df_new['weekday'] = df_new['weekday'].replace(7,0)\n",
    "\n",
    "    # 토요일, 일요일, 공휴일 일때 휴일 1로 지정 \n",
    "    df_new['holiday'] = np.where((df_new['holiday'] == 1) | (df_new['weekday'].isin([0, 6])), 1, 0)\n",
    "    df_new['holiday'].value_counts()\n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivot_df 함수를 사용하여 all_sub 데이터프레임을 변환하여 time_mel_df에 저장\n",
    "time_mel_df = pivot_df(df_in=all_sub, val_name='flow')\n",
    "\n",
    "# 변환된 데이터프레임인 time_mel_df 출력\n",
    "time_mel_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Division 열의 문자열에서 좌우 공백을 제거(strip)\n",
    "time_mel_df.Division = time_mel_df.Division.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Date' 열의 데이터 타입을 datetime으로 변환\n",
    "time_mel_df['Date'] = pd.to_datetime(time_mel_df['Date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge_holiday 함수를 호출하여 time_mel_df와 holiday 데이터프레임을 병합하여 merged_df에 저장\n",
    "merged_df = merge_holiday(left_df=time_mel_df, right_df=holiday)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_df에서 'Division'과 'flow' 열을 선택하여 pivot 함수를 사용하여 변환\n",
    "flow_df = merged_df[['Division', 'flow']].pivot(columns='Division', values='flow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Division'과 'flow' 열을 제외한 열들을 선택하여 info_df에 저장\n",
    "info_df = merged_df[merged_df.columns.difference(['Division', 'flow'])]\n",
    "\n",
    "# info_df 출력\n",
    "info_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flow_df의 첫 번째 열에 해당하는 값들을 선택하여 NaN이 아닌 행들로 이루어진 get_on_v 데이터프레임 생성\n",
    "get_on_v = pd.DataFrame(flow_df.iloc[:, 0]).dropna()\n",
    "\n",
    "# flow_df의 두 번째 열에 해당하는 값들을 선택하여 NaN이 아닌 행들로 이루어진 get_off_v 데이터프레임 생성\n",
    "get_off_v = pd.DataFrame(flow_df.iloc[:, 1]).dropna()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_on_v와 get_off_v를 reset_index를 사용하여 인덱스 재설정 후, 열 방향(axis=1)으로 병합하여 rec_flow 데이터프레임 생성\n",
    "rec_flow = pd.concat([get_on_v.reset_index(drop=True), get_off_v.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# rec_flow의 열 이름을 'geton'과 'getoff'로 변경\n",
    "rec_flow.columns = ['geton', 'getoff']\n",
    "\n",
    "# 'geton'과 'getoff' 열을 더하여 'get_all' 열 생성\n",
    "rec_flow['get_all'] = rec_flow['geton'] + rec_flow['getoff']\n",
    "\n",
    "# info_df에서 get_on_v의 인덱스에 해당하는 행들을 선택하여 인덱스 재설정 후, rec_flow와 열 방향으로 병합하여 recon_df 데이터프레임 생성\n",
    "recon_df = pd.concat([info_df.loc[get_on_v.index, :].reset_index(drop=True), rec_flow], axis=1)\n",
    "\n",
    "# recon_df 출력\n",
    "recon_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recon_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recon_df.dropna(axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "time_map = {\n",
    "    '05~06': '05:00',\n",
    "    '06~07': '06:00',\n",
    "    '07~08': '07:00',\n",
    "    '08~09': '08:00',\n",
    "    '09~10': '09:00',\n",
    "    '10~11': '10:00',\n",
    "    '11~12': '11:00',\n",
    "    '12~13': '12:00',\n",
    "    '13~14': '13:00',\n",
    "    '14~15': '14:00',\n",
    "    '15~16': '15:00',\n",
    "    '16~17': '16:00',\n",
    "    '17~18': '17:00',\n",
    "    '18~19': '18:00',\n",
    "    '19~20': '19:00',\n",
    "    '20~21': '20:00',\n",
    "    '21~22': '21:00',\n",
    "    '22~23': '22:00',\n",
    "    '23~24': '23:00',\n",
    "    '00~01': '00:00'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Time' 열의 값을 time_map을 사용하여 매핑(mapping)\n",
    "recon_df['Time'] = recon_df['Time'].map(time_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recon_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = pd.read_csv('./weather/2008~2023_weather.csv', encoding='cp949')\n",
    "weather.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# weather 데이터프레임의 '강수량(mm)'와 '적설(cm)' 열의 NaN 값을 0으로 대체하여 채우기\n",
    "weather[['강수량(mm)', '적설(cm)']] = weather[['강수량(mm)', '적설(cm)']].fillna(0)\n",
    "\n",
    "# 변경된 weather 데이터프레임 출력\n",
    "weather\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '일시' 열의 데이터 타입을 datetime으로 변환\n",
    "weather['일시'] = pd.to_datetime(weather['일시'])\n",
    "\n",
    "# '일시' 열에서 날짜를 추출하여 'Date' 열 생성\n",
    "weather['Date'] = weather['일시'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "# '일시' 열에서 시간을 추출하여 'Time' 열 생성\n",
    "weather['Time'] = weather['일시'].dt.strftime('%H:%M')\n",
    "\n",
    "# 필요없는 열들을 삭제하고 열 이름 변경\n",
    "weather = weather.drop(columns=['지점', '지점명', '일시'])\n",
    "weather.columns = ['Temp', 'Rainfall_amt', 'Wind_speed', 'Humidity', 'Snow_amt', 'Date', 'Time']\n",
    "\n",
    "# 변경된 weather 데이터프레임 출력\n",
    "weather\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 날짜별로 평균을 계산하여 w_mean 데이터프레임 생성\n",
    "w_mean = weather.groupby(['Date']).mean()\n",
    "\n",
    "# 열 이름에 '_mean'을 추가하여 열 이름 변경\n",
    "w_mean.columns = [f'{c}_mean' for c in w_mean.columns]\n",
    "\n",
    "# 날짜별로 강수량과 적설량을 합산하여 w_sum 데이터프레임 생성\n",
    "w_sum = weather.groupby(['Date'])[['Rainfall_amt', 'Snow_amt']].sum()\n",
    "\n",
    "# 열 이름에 '_sum'을 추가하여 열 이름 변경\n",
    "w_sum.columns = [f'{c}_sum' for c in w_sum.columns]\n",
    "\n",
    "# 날짜별로 최고 기온을 계산하여 w_max 데이터프레임 생성\n",
    "w_max = weather.groupby(['Date'])[['Temp']].max()\n",
    "\n",
    "# 열 이름에 '_max'를 추가하여 열 이름 변경\n",
    "w_max.columns = [f'{c}_max' for c in w_max.columns]\n",
    "\n",
    "# 날짜별로 최저 기온을 계산하여 w_min 데이터프레임 생성\n",
    "w_min = weather.groupby(['Date'])[['Temp']].min()\n",
    "\n",
    "# 열 이름에 '_min'을 추가하여 열 이름 변경\n",
    "w_min.columns = [f'{c}_min' for c in w_min.columns]\n",
    "\n",
    "# w_mean, w_sum, w_max, w_min을 열 방향으로 병합하여 w_stats 데이터프레임 생성\n",
    "w_stats = pd.concat([w_mean, w_sum, w_max, w_min], axis=1)\n",
    "\n",
    "# 최고 기온과 최저 기온의 차이를 계산하여 'Temp_diff' 열 생성\n",
    "w_stats['Temp_diff'] = np.abs(w_max.values - w_min.values)\n",
    "\n",
    "# w_stats를 데이터프레임으로 변환하고 인덱스를 재설정\n",
    "w_stats = pd.DataFrame(w_stats).reset_index(drop=False)\n",
    "\n",
    "# w_stats 출력\n",
    "display(w_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weather와 w_stats를 'Date' 열을 기준으로 left 조인하여 weather 데이터프레임에 추가\n",
    "weather = pd.merge(left=weather, right=w_stats, how='left', on='Date')\n",
    "\n",
    "# 변경된 weather 데이터프레임 출력\n",
    "weather\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_weather(sub_df, weather_df):\n",
    "    \"\"\"\n",
    "    지하철 데이터와 날씨 데이터를 병합하는 함수입니다.\n",
    "    \n",
    "    Args:\n",
    "        sub_df (DataFrame): 지하철 데이터프레임.\n",
    "        weather_df (DataFrame): 날씨 데이터프레임.\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: 병합된 지하철-날씨 데이터프레임.\n",
    "    \"\"\"\n",
    "    # 날짜 열을 datetime 형식으로 변환\n",
    "    sub_df['Date'] = pd.to_datetime(sub_df['Date'])\n",
    "    weather_df['Date'] = pd.to_datetime(weather_df['Date'])\n",
    "    \n",
    "    # 지하철과 날씨 데이터를 날짜와 시간을 기준으로 left 조인하여 병합\n",
    "    subway_weather_df = pd.merge(sub_df, weather_df, on=['Date', 'Time'], how='left')\n",
    "    \n",
    "    # 날짜와 시간을 기준으로 정렬\n",
    "    subway_weather_df.sort_values(['Date', 'Time'], inplace=True)\n",
    "    subway_weather_df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # 시간, 연도, 월, 일을 추출하여 열로 추가\n",
    "    subway_weather_df['hour'] = pd.to_datetime(subway_weather_df['Time']).dt.hour\n",
    "    subway_weather_df[\"year\"] = subway_weather_df[\"Date\"].dt.year\n",
    "    subway_weather_df[\"month\"] = subway_weather_df[\"Date\"].dt.month\n",
    "    subway_weather_df[\"day\"] = subway_weather_df[\"Date\"].dt.day\n",
    "    \n",
    "    return subway_weather_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recon_df와 weather를 이용하여 merge_weather 함수를 호출하여 dfnew_all에 저장\n",
    "dfnew_all = merge_weather(sub_df=recon_df, weather_df=weather)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfnew_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfnew_all.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfnew_all = dfnew_all.drop(dfnew_all[dfnew_all['get_all'] == 0].index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfnew_all.dropna(axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfnew_all.to_csv('./2008~2023_data.csv',encoding='cp949', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_to_parquet(csv_path, save_name):\n",
    "    df = pd.read_csv(csv_path, encoding='cp949')\n",
    "    df.to_parquet(f'./{save_name}.parquet')\n",
    "    del df\n",
    "    gc.collect()\n",
    "    print(save_name, 'Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_to_parquet('./2008~2023_data.csv', '2008~2023_data')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

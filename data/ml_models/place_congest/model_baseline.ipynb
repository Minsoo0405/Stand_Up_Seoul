{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 사용 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime\n",
    "import joblib\n",
    "import os\n",
    "from plugins import connector\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def extract_data(cur, sql):\n",
    "    cur.execute(sql)\n",
    "    columns = [desc[0] for desc in cur.description]\n",
    "    results = cur.fetchall()\n",
    "    print(f'{len(results)}행 추출 완료')\n",
    "    df = pd.DataFrame(results)\n",
    "    df.columns = columns\n",
    "    print('데이터프레임 생성 완료')\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REDSHIFT 데이터 추출(sql 쿼리는 원하면 수정)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn, cur = connector.redshift_connector()\n",
    "\n",
    "# sql 수정 후에 사용해도 좋음\n",
    "# 내가 생각하기에 쓸모 없다고 생각하는 데이터는 뺐음\n",
    "sql = '''\n",
    "    SELECT\n",
    "        P.place_id,\n",
    "        P.area_congest_id,\n",
    "        P.area_ppltn_min,\n",
    "        P.area_ppltn_max,\n",
    "        W.temp,\n",
    "        W.sensible_temp,\n",
    "        W.humidity,\n",
    "        W.wind_dirct,\n",
    "        W.wind_spd,\n",
    "        W.precipitation,\n",
    "        W.uv_index_lvl,\n",
    "        W.pm25,\n",
    "        W.pm10,\n",
    "        W.air_idx_mvl,\n",
    "        DATE_PART('year', W.created_date) AS year,\n",
    "        DATE_PART('month', W.created_date) AS month,\n",
    "        DATE_PART('day', W.created_date) AS day,\n",
    "        DATE_PART('hour', W.created_date) AS hour,\n",
    "        DATE_PART('minute', W.created_date) AS minute,\n",
    "        EXTRACT(DOW FROM W.created_date) AS dow\n",
    "    FROM\n",
    "        \"raw\".\"population\" AS P\n",
    "    JOIN\n",
    "        \"raw\".\"weather\" AS W ON P.place_id = W.place_id AND P.created_date = W.created_date;\n",
    "    '''\n",
    "    \n",
    "df = extract_data(cur, sql)\n",
    "df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 학습 및 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용 컬럼 정의(호영이 골라도됨)\n",
    "# dow는 요일 -> 0 : 일요일, 1 : 월요일 , 2 : 화요일, 3: 수요일, 4: 목요일, 5: 금요일, 6 : 토요일\n",
    "use_columns = ['place_id', 'area_congest_id', 'temp', 'humidity', 'pm25', 'pm10', 'year', 'month', 'hour', 'dow']\n",
    "df = df[use_columns]\n",
    "\n",
    "# categorical_feature\n",
    "categorical_feature = ['place_id', 'area_congest_id', 'year', 'month', 'hour', 'dow']\n",
    "df[categorical_feature] = df[categorical_feature].astype('int').astype('category')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특성과 타겟 데이터 분할\n",
    "X = df[['place_id','temp', 'humidity', 'pm25', 'pm10', 'year', 'month', 'hour', 'dow']]\n",
    "y = df['area_congest_id']\n",
    "\n",
    "# K-Fold 교차 검증 수행\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracy_scores = []\n",
    "\n",
    "for train_idx, test_idx in kfold.split(X):\n",
    "    # 훈련 세트와 테스트 세트 분할\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "    # Random Forest 모델 생성 및 학습\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # 테스트 세트에 대한 예측\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # 정확도 평가 및 저장\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracy_scores.append(accuracy)\n",
    "\n",
    "# 평균 정확도 계산\n",
    "mean_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n",
    "print('Mean Accuracy:', mean_accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 정확도 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 정확도 시각화\n",
    "fold_labels = [f'Fold {i+1}' for i in range(len(accuracy_scores))]\n",
    "plt.bar(fold_labels, accuracy_scores)\n",
    "plt.axhline(mean_accuracy, color='r', linestyle='--', label='Mean Accuracy')\n",
    "plt.xlabel('Fold')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy Scores')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 저장 및 S3 업로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장\n",
    "now_dt = datetime.now().strftime('%Y%m%d')\n",
    "model_path = f'./model/random_forest_model_{now_dt}.pkl'\n",
    "filePath, fileName = os.path.split(model_path)\n",
    "joblib.dump(model, model_path)\n",
    "\n",
    "\n",
    "# s3 연결\n",
    "s3 = connector.s3_connector()\n",
    "\n",
    "# S3 업로드\n",
    "with open(model_path, 'rb') as file:\n",
    "    s3.put_object(\n",
    "        Body = file,\n",
    "        Bucket = 'standupseoul',\n",
    "        Key = 'models/ml/' + fileName,\n",
    "        # ContentType = 'application/x-pickle\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 로드 및 간이검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load(model_path)\n",
    "\n",
    "o_cnt = 0\n",
    "x_cnt = 0\n",
    "for idx in range(30000,30051):\n",
    "    answer = df.loc[idx, 'area_congest_id']\n",
    "    data = list(df.loc[idx, ['place_id', 'temp', 'humidity', 'pm25', 'pm10','year', 'month', 'hour', 'dow']])\n",
    "    predict = model.predict([data])\n",
    "    \n",
    "    if answer == predict[0]:\n",
    "        print(f'정답 : 정답은 {answer}, 예측값은 {predict}입니다.')\n",
    "        o_cnt +=1\n",
    "    else:\n",
    "        print(f'오답 : 정답은 {answer}, 예측값은 {predict}입니다.')\n",
    "        x_cnt +=1\n",
    "\n",
    "print(f'정답 개수는 {o_cnt}')\n",
    "print(f'오답 개수는 {x_cnt}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [42, 24.7, 30, 10, 17, 2023, 6, 19, 13]\n",
    "predict = model.predict([data])\n",
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['area_congest_id'] == 4]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spotify",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
